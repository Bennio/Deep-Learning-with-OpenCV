https://www.pyimagesearch.com/wp-content/uploads/2019/01/keras_regression_classification_vs_reg.png

In this blog, we discuss Keras and deep learning in the context of classification — predicting a label to characterize the contents of an image or an input set of data.

Regression, on the other hand, enables us to predict continuous values. Let’s again consider the task of house price prediction.

As we know, classification is used to predict a class label.

For house price prediction we may define our categorical labels as:

Regression with Keras
labels = {very cheap, cheap, affordable, expensive, very expensive}
1
labels = {very cheap, cheap, affordable, expensive, very expensive}
If we performed classification, our model could then learn to predict one of those five values based on a set of input features.

However, those labels are just that — categories that represent a potential range of prices for the house but do nothing to represent the actual cost of the home.

In order to predict the actual cost of a home, we need to perform regression.

Using regression we can train a model to predict a continuous value.

For example, while classification may only be able to predict a label, regression could say:

“Based on my input data, I estimate the cost of this house to be $781,993.”

The dataset we’ll be using today is from 2016 paper, House price estimation from visual and textual features, by Ahmed and Moustafa.

The dataset includes both numerical/categorical attributes along with images for 535 data points, making it and excellent dataset to study for regression and mixed data prediction.

The house dataset includes four numerical and categorical attributes:

Number of bedrooms
Number of bathrooms
Area (i.e., square footage)
Zip code
These attributes are stored on disk in CSV format.

We’ll be loading these attributes from disk later in this tutorial using pandas , a popular Python package used for data analysis.

A total of four images are also provided for each house:

Bedroom
Bathroom
Kitchen
Frontal view of the house
The end goal of the houses dataset is to predict the price of the home itself.

--------------------------------------

datasets.py : Our script for loading the numerical/categorical data from the dataset
models.py : Our Multi-Layer Perceptron architecture implementation
In datasets.py
\\\\\\\\\\\\\\\\\

df : Our data frame generated by pandas (the previous function helps us to drop some records from the data frame)
train : Our training data for the House Prices Dataset
test : Our testing data.
Then on Line 37, we define the columns of our our continuous data, including bedrooms, bathrooms, and size of the home.

We’ll take these values and use scikit-learn’s MinMaxScaler  to scale the continuous features to the range [0, 1] 
Now we need to pre-process our categorical features, namely the zip code:

--------------------------------
PART2:We’ll then create two Python helper functions:

The first one will be used to load our house price images from disk
The second method will be used to construct our Keras CNN architecture
Finally, we’ll implement our training script and then train a Keras CNN for regression prediction.

As you’ll find out in the rest of today’s tutorial, performing regression with CNNs and Keras is as simple as:

Removing the fully-connected softmax classifier layer typically used for classification
Replacing it with a fully-connected layer with a single node along with a linear activation function.
Training the model with a continuous value prediction loss function such as mean squared error, mean absolute error, 
mean absolute percentage error, etc.

###################
As we know, our house prices dataset includes four images associated with each house:

Bedroom
Bathroom
Kitchen
Frontal view of the house
But how are we going to use these images to train our CNN?

We essentially have three options:

*Pass the images one at a time through the CNN and use the price of the house as the target value for each image
*Utilize multiple inputs with Keras and have four independent CNN-like branches that eventually merge into a single output
*Create a montage that combines/tiles all four images into a single image and then pass the montage through the CNN.

Instead, we should choose the third option where we combine all four images into a single image and then pass
 that image through the CNN (as depicted in Figure 2 above).

For each house in our dataset, we will create a corresponding tiled image that that includes:

The bathroom image in the top-left
The bedroom image in the top-right
The frontal view in the bottom-right
The kitchen in the bottom-left
This tiled image will then be passed through the CNN using the house price as the target predicted value.

The benefit of this approach is that we are:

Allowing the CNN to learn from all photos of the house rather than trying to pass the house photos through the CNN one at a time
Enabling the CNN to learn discriminative filters from all house photos at once (i.e., not “confusing” the CNN with different images with identical target predicted values)